from vox2vec.eval.btcv.data import BTCV
from diffusion4med.models.diffusion.inference import ProbingModified, Backbone
from diffusion4med.models.diffusion import FPN3d, Diffusion, CosineSheduler
from thunder.placeholders import GroupName
from thunder.torch.loggers import WandbLogger
from lightning import Trainer
from thunder.callbacks import TimeProfiler
from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor
from ira.nets.fpn import FPNSegmentationHead


SPACING = 1.0, 1.0, 2.0
PATCH_SIZE = 128, 128, 32
WINDOW_HU = -1350, 1000
BATCH_SIZE = 5
NUM_BATCHES_PER_EPOCH = 1000
NUM_WORKERS = 0
SPLIT = 0


btcv_data = BTCV(
    root="/shared/data/beyond_carnival_vault",
    spacing=SPACING,
    window_hu=WINDOW_HU,
    patch_size=PATCH_SIZE,
    batch_size=BATCH_SIZE,
    num_batches_per_epoch=NUM_BATCHES_PER_EPOCH,
    num_workers=NUM_WORKERS,
    prefetch_factor=None,
    split=SPLIT,
)
train_data = btcv_data.train_dataloader()
val_data = btcv_data.val_dataloader()

timesteps = 300
channels = (32, 64, 128, 256, 512, 1024)
times = [15, 45, 75]
in_channels = 1
n_block = 20
path_to_ckpt = "/shared/experiments/diffusion/kek/public/New_Huge_MedDiffusion_300_switch/Public/ae1lo7m5/checkpoints/last.ckpt"
num_blocks = (
    (n_block, n_block),
    (n_block, n_block),
    (n_block, n_block),
    (n_block, n_block),
    (n_block, n_block),
)
model = FPN3d(
    in_channels=in_channels,
    timesteps=timesteps,
    channels=channels,
    num_blocks=num_blocks,
)

diffusion = Diffusion(
    backbone=model,
    head=None,
    timesteps=timesteps,
    scheduler=CosineSheduler,
    num_log_images=10,
    slice_visualize=None,
    criterion=None,
    lr=None,
    image_shape=(1, *PATCH_SIZE),
)

backbone = Backbone(diffusion, times=times, path_to_ckpt=path_to_ckpt)
head = FPNSegmentationHead(
    num_classes=13, channels=tuple(c * len(times) for c in channels)
)
module = ProbingModified(backbone, head)

wandb_logger = WandbLogger(
    name=GroupName, project="Public", remove_dead_duplicates=True
)

trainer = Trainer(
    callbacks=[
        ModelCheckpoint(save_last=True),
        TimeProfiler(),
        LearningRateMonitor("epoch"),
    ],
    accelerator="gpu",
    devices=1,
    max_epochs=10000,
    logger=wandb_logger,
    num_sanity_val_steps=0,
)
